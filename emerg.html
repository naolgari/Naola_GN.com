<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>emerging</title>
    <style>
        body{
   background-color: antiquewhite;
    padding-left: 20px ;
    padding-right: 20px;
    text-align: center;
    }
h1{
    text-align: center;
}
p{
    margin: 60px;
}
li a{
    float: right;
    background-color: rgb(255, 0, 0);
    text-decoration: none;
    border-radius: 15px;
    text-decoration: none;
    list-style-type: none;
}
.uuu{
    color: rgb(75, 44, 44);
    align-items: center;
    text-align: center;
    justify-content: center;
    align-content: center;
    text-decoration: none;
    list-style-type: none;
    font-family: cursive;
    background-color: rgb(203, 52, 52);
       
     border-width: 90%;
    height: 90px;
    }
.uuu:hover{
        color: rgb(0, 0, 0);
        background-color: rgb(255, 0, 0);
   

}
li a:hover{
    color: black;
    background-color: rgb(43, 255, 0);

    </style>
   
</head>
<body>
    <h1 class="uuu">>>>>>>NAOLA SCHOOL ACADAMIY>>>>>>>></h1>
    <h1>EMERGING</h1>
    <li><a href="index.html" class="hh"><h3>HOME</h2></a></li
    <h1>chapter one</h1>
    <div class="pp">
        <p><h2>
        
        Chapter Two Review Questions
        1. Define data science; what are the roles of a data scientist?
<p>2. Discuss data and its types from computer programming and data analytics perspectives?
. Discuss data and its types from computer programming and data analytics perspectives?
3. Discuss a series of steps needed to generate value and useful insights from data?
4. What is the principal goal of data science?
5. List out and discuss the characteristics of Big Data?
6. How we ingest streaming data into Hadoop Cluster?
35
<img src="https://media.istockphoto.com/id/1469193295/photo/program-development-with-artificial-intelligence-robots-the-use-of-ai-programmers-developing.webp?b=1&s=170667a&w=0&k=20&c=8Khuxy7ogGt9L2cTZFKAqDSONFjRtF6NVciDyG4QVxw=" alt="">
Chapter 3: Artificial Intelligence (AI)
Introduction
In the previous chapter you have been studied about data science, how data acquisition, analyzed
and stored. Basic concepts of big data were also studied. In this chapter, artificial intelligence,
history, types, and applications in different sectors are studied. Finally, some tools and platforms,
as well as a real sample of AI applications, are discussed.
After completing this chapter, the students will be able to:
➢ Explain what artificial intelligence (AI) is.
➢ Describe the eras of AI.
➢ Explain the types and approaches of AI.
➢ Describe the applications of AI in health, agriculture, business and education
➢ List the factors that influenced the advancement of AI in recent years.
➢ Understand the relationship between the human’s way of thinking and AI systems
➢ Identify AI research focus areas.
➢ Identify real-world AI applications, some platforms, and tools.
3.1. What is Artificial Intelligence (AI)
Artificial Intelligence is composed of two words Artificial and Intelligence.
Activity 3.1
➢ How do you define the word Artificial? And the word Intelligence?
Artificial defines "man-made," and intelligence defines "thinking power", or “the ability to learn
and solve problems” hence Artificial Intelligence means "a man-made thinking power."
So, we can define Artificial Intelligence (AI) as the branch of computer science by which we can
create intelligent machines which can behave like a human, think like humans, and able to make
decisions.</p><p>
Intelligence, as we know, is the ability to acquire and apply knowledge. Knowledge is the
information acquired through experience. Experience is the knowledge gained through exposure
(training). Summing the terms up, we get artificial intelligence as the “copy of something natural
36
(i.e., human beings) ‘WHO’ is capable of acquiring and applying the information it has gained
through exposure.”
Activity 3.2
➢ What do you think to make the machine think and make a decision like human beings
do?
Artificial Intelligence exists when a machine can have human-based skills such as learning,
reasoning, and solving problems with Artificial Intelligence you do not need to preprogram a
machine to do some work, despite that you can create a machine with programmed algorithms
which can work with own intelligence.
Intelligence is composed of:
➢ Reasoning
➢ Learning
➢ Problem Solving
➢ Perception
➢ Linguistic Intelligence
An AI system is composed of an agent and its environment. An agent (e.g., human or robot) is
anything that can perceive its environment through sensors and acts upon that environment through
effectors. Intelligent agents must be able to set goals and achieve them. In classical planning
problems, the agent can assume that it is the only system acting in the world, allowing the agent
to be certain of the consequences of its actions. However, if the agent is not the only actor, then it
requires that the agent can reason under uncertainty. This calls for an agent that cannot only assess
its environment and make predictions but also evaluate its predictions and adapt based on its
assessment. Machine perception is the ability to use input from sensors (such as cameras,
microphones,</p> <p>sensors, etc.) to deduce aspects of the world. e.g., Computer Vision.
High-profile examples of AI include autonomous vehicles (such as drones and self-driving cars),
medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games
(such as Chess or Go), search engines (such as Google search), online assistants (such as Siri),
37
image recognition in photographs, spam filtering, prediction of judicial decisions and targeting
online advertisements
AI deals with the area of developing computing systems that are capable of performing tasks that
humans are very good at, for example recognizing objects, recognizing and making sense of
speech, and decision making in a constrained environment.
The advent of Big Data, driven by the arrival of the internet, smart mobile and social media has
enabled AI algorithms, in particular from Machine Learning and Deep Learning, to leverage Big
Data and perform their tasks more optimally. This combined with cheaper and more powerful
hardware such as Graphical Processing Units (GPUs) has enabled AI to evolve into more complex
architectures. Machine Learning is an advanced form of AI where the machine can learn as it goes
rather than having every action programmed by humans.
Many times, students get <img src="https://media.istockphoto.com/id/1321462048/photo/digital-transformation-concept-system-engineering-binary-code-programming.webp?b=1&s=170667a&w=0&k=20&c=8HOUiG9_M3Nm2TKS-EiGI8XdZctk7502R7s8NbCTm88=" alt=""> onfused between Machine Learning and Artificial Intelligence (see
figure 3.1), but Machine learning, a fundamental concept of AI research since the field’s inception,
is the study of computer algorithms that improve automatically through experience. The term
machine learning was introduced by Arthur Samuel in 1959. Neural networks are biologically
inspired networks that extract features from the data in a hierarchical fashion. The field of neural
networks with several hidden layers is called deep learning.
Figure 3.1 Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL)
38
3.1.1. Need for Artificial Intelligence
Activity 3.3
➢ Why we need AI at this time?
1. To create expert systems that exhibit intelligent behavior with the capability to learn,
demonstrate, explain and advice its users.
2. Helping machines find solutions to complex problems like humans do and applying them
as algorithms in a computer-friendly manner.</p><p>
3.1.2. Goals of Artificial Intelligence
Activity 3.4
➢ You have been learned about AI and the need for it. What do you think the main goal of
the advancement in AI?
Following are the main goals of Artificial Intelligence:
1. Replicate human intelligence
2. Solve Knowledge-intensive tasks
3. An intelligent connection of perception and action
4. Building a machine which can perform tasks that requires human intelligence such as:
✓ Proving a theorem
✓ Playing chess
✓ Plan some surgical operation
✓ Driving a car in traffic
5. Creating some system which can exhibit intelligent behavior, learn new things by itself,
demonstrate, explain, and can advise to its user.
3.1.3. What Comprises to Artificial Intelligence?
Activity 3.5
➢ To make a machine learn and make a decision like humans do, AI requires the knowledge
of some disciplines. Write down some disciplines which AI requires?
Artificial Intelligence is not just a part of computer science even it's so vast and requires lots of
other factors that can contribute to it. To create the AI-first we should know that how intelligence
39
is composed, so Intelligence is an intangible part of our brain which is a combination of Reasoning,
learning, problem-solving, perception, language understanding, etc.
To achieve the above factors for a machine or software Artificial Intelligence requires the
following disciplines (see Figure 3.2):</p>
<p>
✓ Mathematics
✓ Biology
✓ Psychology
✓ Sociology
✓ Computer Science
✓ Neurons Study
✓ Statistics
Figure 3.2 Artificial Intelligence is multidisciplinary
3.1.4. Advantages of Artificial Intelligence
Activity 3.6
➢ What do we get from using AI technology instead of previous reactive technology?
40
Following are some main advantages of Artificial Intelligence:
➢ High Accuracy with fewer errors: AI machines or systems are prone to fewer errors
and high accuracy as it takes decisions as per pre-experience or information.
➢ High-Speed: AI systems can be of very high-speed and fast-decision making, because
of that AI systems can beat a chess champion in the Chess game.
➢ High reliability: AI machines are highly reliable and can perform the same action
multiple times with high accuracy.
➢ Useful for risky areas: AI machines can be helpful in situations such as defusing a
bomb, exploring the ocean floor, where to employ a human can be risky.
➢ Digital Assistant: AI can be very useful to provide digital assistant to users such as AI
technology is currently used by various E-commerce websites to show the products as
per customer requirements.
➢ Useful as a public utility: AI can be very useful for public utilities such as a self-
driving car which can make our journey safer and hassle-free, facial recognition for
security purposes, Natural language processing (for search engines, for spelling
checker, for assistant like Siri, for translation like google translate), etc.
3.1.5. Disadvantages of Artificial Intelligence
Activity 3.7
➢ As we all know, engineering is a tradeoff; improving or enhancing in one aspect will
lead you to worsen or deteriorating in another aspect. In the previous chapter, we have
learned the advantages of AI; write down some disadvantages of AI?
One of the key <img src="https://images.unsplash.com/photo-1461749280684-dccba630e2f6?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8Mnx8dGVjaG5vbG9neSUyMGltYWdlfGVufDB8fDB8fHww&auto=format&fit=crop&w=600&q=60" alt=""> features that distinguishes us, humans, from everything else in the world is
intelligence. This ability to understand, apply knowledge and improve skills has played a
significant role in our evolution and establishing human civilization. But many people (including
Elon Musk the founder of ….) believe that the advancement in technology can create a
superintelligence that can threaten human existence.
Every technology has some disadvantages, and the same goes for Artificial intelligence. Being so
advantageous technology still, it has some disadvantages which we need to keep in our mind while
creating an AI system. Following are the disadvantages of AI:
101
In the context of digital privacy, individual privacy is the notion that individuals have a right to
exist freely on the internet, in that they can choose what types of information they are exposed to,
and more importantly that unwanted information should not interrupt them An example of a digital
breach of individual privacy would be an internet user receiving unwanted ads and emails/spam,
or a computer virus that forces the user to take actions they otherwise wouldn't. In such cases the
individual, during that moment, doesn't exist digitally without interruption from unwanted
information; thus, their individual privacy has been infringed upon.
6.3.4. Some digital privacy principles</p>
<p>
Activity 6.13
➢ Give some examples you have to consider to make your data as well as communication
private?
➢ Data Minimization: collect the minimal amount of information necessary from individuals
and businesses consistent with the Department’s mission and legal requirements.
➢ Transparency: Notice covering the purpose of the collection and use of identifiable
information will be provided in a clear manner. Information collected will not be used for
any other purpose unless authorized or mandated by law.
➢ Accuracy: Information collected will be maintained in a sufficiently accurate, timely, and
complete manner to ensure that the interests of the individuals and businesses are protected.
➢ Security: Adequate physical and IT security measures will be implemented to ensure that
the collection, use, and maintenance of identifiable information are properly safeguarded
and the information is promptly destroyed in accordance with approved records control
schedules.
6.4. Accountability and trust
Activity 6.14
➢ Why are accountability and trust so important in using emerging technologies?
When emerging technology creates far-reaching and rapid change, it can also bring new risks.
Understanding and mitigating them will help to build confidence. Often legal and regulatory
frameworks haven’t kept pace with digital transformation, and organizations are seeking guidance.
102
This challenge is exacerbated by the speed at which technological change is occurring and the
breadth of its adoption – which is introducing new risks that demand new responses.
Emerging technologies can provide improved accuracy, better quality and cost efficiencies for
businesses in every sector. They can enhance trust in the organization’s operations and financial
processes, which is crucial for sustainable success. But this can produce a paradox: the very
solutions that can be used to better manage risk, increase transparency and build confidence are
often themselves the source of new risks, which may go unnoticed.
There’s a danger that the use of technology will degrade people’s willingness to judge and
intervene because they feel that they are less personally connected to consumers and consumer
outcomes – the logic of the machine has taken over from individual responsibility.
The obligation of an individual or organization to account for its activities, accept responsibility
for them, and to disclose the results in a transparent manner. It also includes the responsibility for
money or other entrusted property.
6.5. Treats and challenges
6.5.1. Ethical and regulatory challenges
Activity 6.15
➢ What are the challenges of using technologies like AI, IoT, and big data?
With Technology moving at a fast pace it is always been a challenge for Security. As security
professionals, we need to keep pace with ever-changing technology and be aware of the AI, IoT,
Big Data, Machine Learning, etc. It is no more Guards, guns & gates it is more than that & we
need to play a major role for a security professional to support business or rather we should be able
to understand the language of business and talk to the leaders in their language. With Growing
needs Cyber & Data Security is getting prominence that requires security practitioners to focus on
the business need for securing data, understanding security and risk from a business perspective
by extensively interacting with the business community in understanding their requirements or
what they want.</p><p>
103
Activity 6.16
➢ What role can technologies such as AI, IoT, Machine Learning and Big Data play in
enhancing the security of an organization?
Emerging technologies are already impacting how we live and work. They're also changing how
we approach, plan, and integrate security operations. Certainly, we are living in an era where
innovation, agility, and imagination are all essential in order to keep pace with the exponential
technological transformation taking place. For security, both physical and cyber, the equation is
the same catalyzing many new potential applications for emerging technologies. Emerging
technologies are making an impact include:
1. Counter-terrorism and law enforcement informatics via predictive analytics and artificial
intelligence.
2. Real-time horizon scanning and data mining for threats and information sharing
3. Automated cybersecurity and information assurance
4. Enhanced Surveillance (chemical and bio-detection sensors, cameras, drones, facial
recognition, license plate readers)
5. Simulation and augmented reality technologies for training and modeling
6. Safety and security equipment (including bullet and bomb proof) made with lighter and
stronger materials
7. Advanced forensics enabled by enhanced computing capabilities (including future
quantum computing)
8. Situational awareness capabilities via GPS for disaster response and crisis response
scenarios
9. Biometrics: assured identity security screening solutions by bio-signature: (every aspect of
your physiology can be used as a bio-signature. Measure unique heart/pulse rates,
electrocardiogram sensor, blood oximetry, skin temperature)
10. Robotic Policing (already happening in Dubai!)
104</p><p>
6.5.1.1. Challenges in using Artificial Intelligence
Activity 6.17
➢ AI has a wide application in health and manufacturing industries. What are the
challenges the world face when implementing the applications of AI in the previously
mentioned industries?
AI is only as good as the data it is exposed to, which is where certain challenges may present
themselves. How a business teaches and develops its AI will be the major factor in its usefulness.
Humans could be the weak link here, as people are unlikely to want to input masses of data into a
system.
Another dilemma that comes along with AI is its potential to replace human workers. As machines
become more “intelligent” they could begin to replace experts in higher-level jobs. Alternatively,
AI also has the potential to take the burden of laborious and time-consuming tasks from these
people, freeing up their time and brainpower for other things e.g. doctors using diagnostic AI to
help them diagnose patients will analyze the data presented by the AI and make the ultimate
decision. Managing the challenges posed by AI will require careful planning to ensure that the full
benefits are realized and risks are mitigated.
6.5.1.2. Challenges in using Robotics in manufacturing
Activity 6.18
➢ Write down the challenges of using robots in the manufacturing industry? Debate on the
pros and cons of giving jobs to humans or to robots in the manufacturing industry?
With automation and robotics moving from production lines out into other areas of work and
business, the potential for humans losing jobs is great here too. As automation technologies
become more advanced, there will be a greater capability for automation to take over more and
more complex jobs. As robots learn to teach each other and themselves, there is the potential for
much greater productivity but this also raises ethical and cybersecurity concerns.
105
6.5.1.3. Challenges in using the Internet of Things
Activity 6.19
➢ As we discussed in chapter 4, IoT has a vast application in different sectors. Write down
some challenges of using IoT in our daily activities?
As more and more connected devices (such as smartwatches and fitness trackers) join the Internet
of Things (IoT) the amount of data being generated is increasing. Companies will have to plan
carefully how this will affect the customer-facing application and how to best utilize the masses
of data being produced. There are also severe security implications of mass connectivity that need
to be addressed.</p><p>
6.5.1.4. Challenges in Big Data
Almost all the technologies mentioned above have some relation to Big Data. The huge amount of
data being generated on a daily basis has the potential to provide businesses with better insight
into their customers as well as their own business operations.
Although data can be incredibly useful for spotting trends and analyzing impacts, surfacing all this
data to humans in a way that they can understand can be challenging. AI will play a role here.
6.5.2. Treats
Activity 6.20
➢ Write down some risks in emerging technologies like driverless cars, drones, and IoT?
New and emerging technologies pose significant opportunities for businesses if they utilize them
well and understand their true value early on. They also pose risks and questions not only to
business but to society as a whole. Planning for how to deal with these emerging technologies and
where value can be derived while assessing potential risks before they become a fully-fledged
reality is essential for businesses that want to thrive in the world of AI, Big Data and IoT.
Some risks of emerging technology are:
➢ Driverless car: while a compelling option for future fleer cars, companies could crash and
burn from claims related to bodily injury and property damage.
➢ Wearables: Google glass, Fitbit and other wearables can expose companies to the invasion
of privacy claims that may not be covered by general liability or personal injury claims that
weren’t foreseen.
107
Chapter Six Review Questions
1. What is the importance of ethics in emerging technologies?
2. List down some general ethical rules?
3. List down some professional responsibility related to ethical rules
4. What is digital privacy? What is its importance?
5. Briefly explain digital privacy principles
6. Why we need accountability in using emerging technologies?
7. Is the trust necessary to use an emerging technology platform? Why?
8. Briefly explain the challenges in using:
a. AI?
b. Robots?
c. IoT?
9. Briefly explain the risks we face in augmented reality, IoT and AI?
10. Do you think that dealing with big data demands high ethical regulations, accountability,
and responsibility of the person as well as the company? Why?</p>
108 <p>
Chapter 7: Other emerging technologies
Introduction
Dear students, in the previous chapter, you had studied some emerging technologies like data
science, artificial intelligence, the internet of things and augmented reality and their ethical issues.
In this chapter, you are going to discuss other emerging technologies like nanotechnology,
biotechnology, block-chain technology, cloud and quantum computing, autonomic computing,
computer vision, embedded systems, cybersecurity, and 3D printing.
After accomplishing this chapter, Students will be able to:
➢ Explain nanotechnology and its application in different sectors.
➢ Explain biotechnology and its application in different sectors.
➢ Explain block-chain technology and its application.
➢ Has gain insights about the cloud, quantum and autonomic computing, their differences,
and applications.
➢ Explain how computer vision works and its application.
➢ Identify and explain embedded systems and their pros and cons.
➢ Describe cybersecurity, types of cybersecurity treat and its benefits.
➢ Distinguish the difference between additive manufacturing and 3D printing.
7.1.Nanotechnology
Activity 7.1
➢ Explain Nanoscale? Compare it with meters? Give examples in Nanoscale?
Nanotechnology is science, engineering, and technology conducted at the nanoscale, which is
about 1 to 100 nanometers. Nanoscience and nanotechnology are the study and application of
extremely small things and can be used across all the other science fields, such as chemistry,
biology, physics, materials science, and engineering.
7.1.1. How it started
Activity 7.2
➢ What do you think the need to study materials in Nanoscale?
The ideas and concepts behind nanoscience and nanotechnology started with a talk entitled
“There’s plenty of room at the bottom” by physicist Richard Feynman at an American Physical
Society meeting at the California Institute of Technology (CalTech) on December 29, 1959, long
</p>
            <p>137
            7.9.2. Additive Manufacturing: A Bytes-to-Parts Supply Chain
            “Additive manufacturing” (AM) is a big-picture term more at home in the boardroom than the
            factory floor or garage. Naturally, AM separates itself from older, subtractive technologies like
            milling. Otherwise, the term is less about the 3D printer itself, and more about the manufacturing
            process transformed by 3D printing.
            What is that transformation? AM changes the way we think about inventory and supply chain,
            taking parts from the point of manufacture to the point of use?
            AM is flexible in the time it takes to load a file, from anywhere in the world. It enables customized
            parts, in volume, and involves stocking raw materials like filament and printing spare parts on
            demand</p><p>
            Additive manufacturing (AM) describes types of advanced manufacturing that are used to create
            three-dimensional structures out of plastics, metals, polymers and other materials that can be
            sprayed through a nozzle or aggregated in a vat. These constructs are added layer by layer in real-
            time based on digital design. The simplicity and low cost of AM machines, combined with the
            scope of their potential creations, could profoundly alter global and local economies and affect
            international security.
            138
            Chapter Seven Review Questions
            1. What is nanotechnology? Write down some applications of nanotechnology?
            2. Briefly explain biotechnology and its importance in agriculture, medicine, and the
            environment?
            3. What is Blockchain technology? Briefly explain how it works?
            4. Briefly explain cloud and quantum computing?
            5. What is autonomic computing? Write down some of its characteristics?
            6. What is Computer vision? List down some real-world applications?
            7. Briefly explain embed systems and its components?</p><p>
            8. What is cybersecurity? List some cybersecurity treats? Write down the advantages of
            cybersecurity?
            9. Briefly explain additive manufacturing?
            139
            Bibliography
            E. S. Ruiz and F. M. U. R. Perez, “German carro fernandez, sergio martin gutierrez, elio
            sancristobal ruiz, francisco mur perez, and manuel castro gil ©,” no. June, pp. 51–58, 2012.
            F. Griffiths and M. Ooi, “The fourth industrial revolution - Industry 4.0 and IoT [Trends in Future
            I&M],” IEEE Instrum. Meas. Mag., vol. 21, pp. 29–43.
            M. Maier, S. Member, and M. Lévesque, “Dependable Fiber-Wireless ( FiWi ) Access Networks
            and Their Role in a Sustainable Third Industrial Revolution Economy,” vol. 63, no. 2, pp. 386–
            400, 2014.
            S. Product, “Revolution Impact : Technology,” no. April, pp. 51–56, 2017.
            J. Y. Park, J. Song, E. Seol, M. Seok, and K. Song, “MON-PO326: Constructing Standardized
            Nursing Practice on Korean Nutrition Support Nurses,” Clin. Nutr., vol. 38, no. 2019, pp. S178–
            S179.</p><p>
            J. Hoerni, “Semiconductors and the second industrial revolution,” pp. 38–39, 1982.
            C. Production, “YEAR 6 : THE INDUSTRIAL REVOLUTION ( 6 lessons ) Lesson 1.
            Introduction to the Industrial Revolution.”
            J. Wan et al., “Software-Defined Industrial Internet of Things in the Context of Industry 4. 0,” vol.
            16, no. 20, pp. 7373–7380, 2016.
            H. Xu, W. Yu, D. Griffith, and N. Golmie, “A Survey on Industrial Internet of Things : A Cyber-
            Physical Systems Perspective,” IEEE Access, vol. PP, no. c, p. 1, 2018.
            Data Science: A Comprehensive Overview LONGBING CAO, University of Technology Sydney,
            Australia 2017
            Smith, F.J., Data science as an academic discipline. Data Science Journal, 5, 2006. pp.163–164.
            Mike Loukides, “What is Data Science?”, O’Reilly Media, Inc.”2011. pp10-22.
            Thomas L. Floyd, “Digital Fundamentals with PLD Programming”, Pearson Prentice Hall, 2006,
            Prakash G. Gupta, “Data Communications and Computer Networking”, Prentice-Hall, 2006
            140
            Martin L. Shoemaker, “Human-Machine Interface”, Independently Published, 2019
            “An Introduction to Big Data Concepts and Terminology” [Online]. Available :
            https://www.digitalocean.com/community/tutorials/an-introduction-to-big-data-concepts-and-
            terminology [Accessed: September 7, 2019]</p><p>
            “Data Types: Structured vs. Unstructured Data” [Online]. Available:
            https://www.bigdataframework.org/data-types-structured-vs-unstructured-data/ Accessed
            September 7, 2019.
            “What is Data Science? “https://datascience.berkeley.edu/about/what-is-data-science/ [Online].
            Available : [Accessed: September 7, 2019]
            “The Data Value Chain”https://opendatawatch.com/reference/the-data-value-chain-executive-
            summary/ [Online]. Available : [Accessed: September 7, 2019]
            “Big Data Analytics – Data Scientist”
            https://www.tutorialspoint.com/big_data_analytics/data_scientist.htm [Online]. Available :
            [Accessed: September 7, 2019]
            “Introduction of Artificial Intelligence - Javatpoint,” www.javatpoint.com. [Online]. Available:
            https://www.javatpoint.com/introduction-to-artificial-intelligence. [Accessed: 07-Nov-2019].
            “Artificial Intelligence | An Introduction,” GeeksforGeeks, 08-Sep-2017.
            “An introduction to Artificial Intelligence.” [Online]. Available:
            https://hackernoon.com/understanding-understanding-an-intro-to-artificial-intelligence-
            be76c5ec4d2e. [Accessed: 07-Nov-2019].</p><p>
            “AI Overview,” Snips. [Online]. Available: https://snips.ai/content/intro-to-ai/#device-metrics.
            [Accessed: 07-Nov-2019].
            “History of Artificial Intelligence - Javatpoint,” www.javatpoint.com. [Online]. Available:
            https://www.javatpoint.com/history-of-artificial-intelligence. [Accessed: 08-Nov-2019].
            “Top 15 Artificial Intelligence Platforms - Compare Reviews, Features, Pricing in 2019,” PAT
            RESEARCH: B2B Reviews, Buying Guides & Best Practices, 15-Jul-2019. [Online]. Available:
            141
            https://www.predictiveanalyticstoday.com/artificial-intelligence-platforms/. [Accessed: 08-Nov-
            2019].
            “Best AI Platforms Software in 2019 | G2.” [Online]. Available:
            https://www.g2.com/categories/ai-platforms. [Accessed: 08-Nov-2019].
            Brewster, C., Roussaki, I., Kalatzis, N., Doolin, K., & Ellis, K. (2017). IoT in agriculture:
            Designing a Europe-wide large-scale pilot. IEEE communications magazine, 55(9), 26-33.
            Ramakrishna, G.Kiran Kumar, A.Mallikarjuna Reddy, Pallam Ravi (2018). A Survey on various
            IoT Attacks and its Countermeasures. International Journal of Engineering Research in Computer
            Science and Engineering (IJERCSE), 5(4), 2394-2320.
            Elijah, O., Rahman, T. A., Orikumhi, I., Leow, C. Y., & Hindia, M. N. (2018). An overview of the
            Internet of Things (IoT) and data analytics in agriculture: Benefits and challenges. IEEE Internet
            of Things Journal, 5(5), 3758-3773.</p><p>
            Elijah, O., Rahman, T. A., Orikumhi, I., Leow, C. Y., & Hindia, M. N. (2018). An overview of the
            Internet of Things (IoT) and data analytics in agriculture: Benefits and challenges. IEEE Internet
            of Things Journal, 5(5), 3758-3773.
            Foote, K. D. (2016). A brief history of the internet of things. Data Education for Business and IT
            Professionals. Available online: http://www. dataversity. net/brief-history-internet-things/
            (accessed on 12 November 2018).
            Gupta, B. B., & Quamara, M. (2018). An overview of the Internet of Things (IoT): Architectural
            aspects, challenges, and protocols. Concurrency and Computation: Practice and Experience,
            e4946.
            John Terra (2019). Everything You Need to Know About IoT Applications.
            https://www.simplilearn.com/iot-applications-article
            Mohamed, K. S. (2019). The Era of Internet of Things: Towards a Smart World. In the Era of
            Internet of Things (pp. 1-19). Springer, Cham.</p><p>
            Vyas, D. A., Bhatt, D., & Jha, D. (2015). IoT: trends, challenges, and future scope. IJCSC, 7(1),
            186-197.
            142
            Antonioli, M., Blake, C., & Sparks, K. (2014). Augmented reality applications in education. The
            Journal of Technology Studies, 96-107.
            Chavan, S. R. (2016). Augmented Reality Vs Virtual Reality: Differences and
            Similarities. International Journal of Advanced Research in Computer Engineering & Technology
            (IJARCET), 5(6).
            Håkansson, L. (2018). Virtual and Augmented Reality in Marketing.
            Kipper, G., & Rampolla, J. (2012). Augmented Reality: an emerging technologies guide to AR.
            Elsevier.
            Kirner, C., Cerqueira, C., & Kirner, T. (2012). Using augmented reality artifacts in education and
            cognitive rehabilitation. Virtual Reality in Psychological, Medical and Pedagogical Applications
            2 Will-be-set-by-IN-TECH, 247-270.
            Margetis, G., Papagiannakis, G., & Stephanidis, C. (2019). Realistic Natural Interaction with
            Virtual Statues in X-Reality Environments. International Archives of the Photogrammetry,
            Remote Sensing and Spatial Information Sciences, 42(2/W11).</p><p>
            Thimbleby, H. (2013). Technology and the future of healthcare. Journal of public health
            research, 2(3).
            Thomas, B. H. (2012). A survey of visual, mixed, and augmented reality gaming. Computers in
            Entertainment (CIE), 10(1), 3.
            “Ethics and new technologies.” [Online]. Available:
            https://www.icaew.com/technical/ethics/ethics-and-new-technologies. [Accessed: 25-Aug-2019].
            J. Weckert and R. Lucas, Professionalism in the Information and Communication Technology
            Industry. Canberra: ANU Press, 2013.
            “Code of Ethics,” PROFESSIONAL CERTIFICATIONS FOR EMERGING TECH. [Online].
            Available: http://iccp.org/code-of-ethics.html. [Accessed: 25-Aug-2019].
            “IT Privacy Policy, Office of Privacy and Open Government, U.S. Department of Commerce.”
            [Online]. Available: http://www.osec.doc.gov/opog/privacy/digital_policy.html. [Accessed: 25-
            Aug-2019].
            143</p><p>
            “As technology advances, will accountability be a casualty?” [Online]. Available:
            https://www.ey.com/en_gl/banking-capital-markets/as-technology-advances-will-accountability-
            be-a-casualty. [Accessed: 02-Sep-2019].
            “How can you build trust when emerging technologies bring new risks?” [Online]. Available:
            https://www.ey.com/en_gl/digital/how-can-you-build-trust-when-emerging-technologies-bring-
            new-risks. [Accessed: 02-Sep-2019].
            “What comes after those ellipses?,” BusinessDictionary.com. [Online]. Available:
            http://www.businessdictionary.com/definition/accountability.html. [Accessed: 08-Sep-2019].
            “‘Emerging Technologies are Already Impacting Security Strategies,’” IFSEC India, 11-Jan-2019.
            [Online]. Available: https://www.ifsec.events/india/visit/news-and-updates/emerging-
            technologies-are-already-impacting-security-strategies. [Accessed: 02-Sep-2019].
            C. Lovatt, “5 Big Technology Challenges For Enterprises In The Future.” [Online]. Available:
            https://blog.cutover.com/technology-challenges-enterprises-future. [Accessed: 08-Sep-2019].
            “What are the ethical implications of emerging tech?,” World Economic Forum. [Online].
            Available: https://www.weforum.org/agenda/2015/03/what-are-the-ethical-implications-of-
            emerging-tech/. [Accessed: 25-Aug-2019].
            B. Dainow, “Ethics in Emerging Technology,” ITNOW, vol. 56, pp. 16–18, Aug. 2014.
            “7 Emerging Technology Risks,” Risk & Insurance, 04-Aug-2014. [Online]. Available:
            https://riskandinsurance.com/7-emerging-tech-risks/. [Accessed: 08-Sep-2019].
            “12 Examples of Artificial Intelligence: AI Powers Business.” [Online]. Available:
            https://www.datamation.com/artificial-intelligence/examples-of-artificial-intelligence.html.
            [Accessed: 09-Nov-2019]</p><p>
            “What is Nanotechnology? | Nano.” [Online]. Available: https://www.nano.gov/nanotech-
            101/what/definition. [Accessed: 08-Sep-2019].
            “How Nanotechnology Works,” HowStuffWorks, 25-Oct-2007. [Online]. Available:
            https://science.howstuffworks.com/nanotechnology.htm. [Accessed: 08-Sep-2019].
            144
            “Nanotechnology - Definition and Introduction. What is nanotechnology?” Nanowerk. [Online].
            Available:
            https://www.nanowerk.com/nanotechnology/introduction/introduction_to_nanotechnology_1.ph
            p. [Accessed: 08-Sep-2019].
            “Nanotechnology Applications | Nanotechnology Uses.” [Online]. Available:
            https://www.understandingnano.com/nanotech-applications.html. [Accessed: 08-Sep-2019].
            R. M. Divya TN, “Applications of Nanotechnology,” J. Nanomedicine Biotherapeutic Discov.,
            vol. 05, no. 01, 2015.
            “What is Biotechnology?” BIO. [Online]. Available: https://www.bio.org/what-biotechnology.
            [Accessed: 08-Sep-2019].
            C. Fossen, “What is Biotechnology? - Department of Biotechnology and Food Science.” [Online].
            Available: https://www.ntnu.edu/ibt/about-us/what-is-biotechnology. [Accessed: 08-Sep-2019].
            “Benefits & Risks of Biotechnology,” Future of Life Institute. [Online]. Available:
            https://futureoflife.org/background/benefits-risks-biotechnology/. [Accessed: 08-Sep-2019].
            “Biotechnology and its Applications - Study Material for NEET (AIPMT) & Medical Exams |
            askIITians.” [Online]. </p><p>Available: /biology/biotechnology-and-its-applications/. [Accessed: 08-
            Sep-2019].
            “What is Blockchain Technology? A Step-by-Step Guide for Beginners,” Blockgeeks, 18-Sep-
            2016. [Online]. Available: https://blockgeeks.com/guides/what-is-blockchain-technology/.
            [Accessed: 23-Nov-2019].
            “5 applications for blockchain in your business.” [Online]. Available:
            https://execed.economist.com/blog/industry-trends/5-applications-blockchain-your-business.
            [Accessed: 08-Sep-2019].
            L. Fortney, “Blockchain Explained,” Investopedia. [Online]. Available:
            https://www.investopedia.com/terms/b/blockchain.asp. [Accessed: 08-Sep-2019].
            “What is Quantum Cloud Computing?” [Online]. Available: http://quantumly.com/quantum-
            cloud-computer-computing.html. [Accessed: 08-Sep-2019].
            145</p><p>
            H. A. Müller, L. O’Brien, M. Klein, and B. Wood, “Autonomic Computing,” p. 61.
            “What is autonomic computing? - Definition from WhatIs.com,” WhatIs.com. [Online]. Available:
            https://whatis.techtarget.com/definition/autonomic-computing. [Accessed: 02-Sep-2019].
            M. Parashar and S. Hariri, “Autonomic Computing: An Overview,” in Unconventional
            Programming Paradigms, vol. 3566, J.-P. Banâtre, P. Fradet, J.-L. Giavitto, and O. Michel, Eds.
            Berlin, Heidelberg: Springer Berlin Heidelberg, 2005, pp. 257–269.
            C. R. Krishna, “Computer Vision: Foundations and Applications,” p. 213.
            “Computer Vision: What it is and why it matters.” [Online]. Available:
            https://www.sas.com/en_us/insights/analytics/computer-vision.html. [Accessed: 02-Sep-2019].
            R. Szeliski, “Computer Vision: Algorithms and Applications,” p. 979.
            “Embedded Systems - Overview - Tutorialspoint.” [Online]. Available:
            https://www.tutorialspoint.com/embedded_systems/es_overview.htm. [Accessed: 02-Sep-2019].
            “What is Cyber Security? | IT Governance UK.” [Online]. Available:
            https://www.itgovernance.co.uk/what-is-cybersecurity. [Accessed: 02-Sep-2019].
            D. J. Pande, “Introduction to Cyber Security,” p. 152.
            “Cybersecurity: Threats, Challenges, Opportunities,” p. 72.
            “What Is Cybersecurity?” Cisco. [Online]. Available:</p><p>
            https://www.cisco.com/c/en/us/products/security/what-is-cybersecurity.html. [Accessed: 02-Sep-
            2019].
            “What is Cybersecurity? - Definition from WhatIs.com,” SearchSecurity. [Online]. Available:
            https://searchsecurity.techtarget.com/definition/cybersecurity. [Accessed: 02-Sep-2019].
            “3D Printing and Additive Manufacturing – What’s the Difference?” All3DP, 24-Jan-2019.
            [Online]. Available: https://all3dp.com/2/3d-printing-and-additive-manufacturing-what-s-the-
            difference/. [Accessed: 02-Sep-2019].
            T. Johnston, T. Smith, and J. Irwin, Additive Manufacturing in 2040: Powerful Enabler, Disruptive
            Threat. RAND Corporation, 2018.</h2></p>
    </div>
</body>
</html>